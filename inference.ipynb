{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7475a584-99a1-4ae2-bfca-f152e39a09ca",
   "metadata": {},
   "source": [
    "# Minutes Item Segementation via GPT-3.5-Turbo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b594c8-4821-404c-81bf-841350af0e75",
   "metadata": {},
   "source": [
    "## Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b36f2b86-84b4-4000-8c21-94f9a4e27f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eva/miniforge-pypy3/envs/minutes-item-seg/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching each model attached to event_ref: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 56.88it/s]\n",
      "Fetching transcripts: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 47.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from cdp_data import CDPInstances, datasets\n",
    "from cdp_data.utils import connect_to_infrastructure\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to infra\n",
    "connect_to_infrastructure(CDPInstances.Seattle)\n",
    "\n",
    "# Get dataset\n",
    "seattle_df = datasets.get_session_dataset(\n",
    "    CDPInstances.Seattle,\n",
    "    start_datetime=\"2023-01-01\",\n",
    "    end_datetime=\"2023-02-15\",\n",
    "    store_transcript=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f991adf3-645e-463c-927a-1fd2aa3c2be1",
   "metadata": {},
   "source": [
    "## Prompt Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbcfc286-7c37-4f15-87a6-dbef487af1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "from cdp_backend.pipeline.transcript_model import Transcript\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback \n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "class SectionLabels(Enum):\n",
    "    public_comment = \"Public Comment\"\n",
    "\n",
    "ALL_SECTION_LABELS = [item.value for item in SectionLabels]\n",
    "ALL_SECTION_LABELS_STR = \"\\n- \".join(ALL_SECTION_LABELS)\n",
    "ALL_SECTION_LABELS_STR = f\"- {ALL_SECTION_LABELS_STR}\"\n",
    "\n",
    "class MeetingSection(BaseModel):\n",
    "    label: SectionLabels = Field(description=\"the section label\")\n",
    "    first_sentence_text: str = Field(\n",
    "        description=\"the exact copied text of the first sentence of the section\",\n",
    "    )\n",
    "    last_sentence_text: str = Field(\n",
    "        description=\"the exact copied text of the last sentence of the section\",\n",
    "    )\n",
    "\n",
    "class MeetingSegmentation(BaseModel):\n",
    "    sections: list[MeetingSection]\n",
    "\n",
    "MEETING_SEG_PARSER = PydanticOutputParser(pydantic_object=MeetingSegmentation)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "MEETING_SEG_PROMPT = PromptTemplate.from_file(\n",
    "    \"prompts/v0.jinja\",\n",
    "    input_variables=[\"transcript\"],\n",
    "    partial_variables={\n",
    "        \"section_labels\": ALL_SECTION_LABELS_STR,\n",
    "        \"format_instructions\": MEETING_SEG_PARSER.get_format_instructions(),\n",
    "    },\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "def _process_transcript(df: pd.DataFrame, index: int) -> MeetingSegmentation:\n",
    "    # Get the meeting transcript\n",
    "    session_details = df.loc[index]\n",
    "    \n",
    "    # Load transcript\n",
    "    with open(session_details.transcript_path) as open_f:\n",
    "        transcript = Transcript.from_json(open_f.read())\n",
    "\n",
    "    # Convert to string\n",
    "    transcript_str = \"\\n\\n\".join([s.text for s in transcript.sentences[:200]])\n",
    "    \n",
    "    # Fill the prompt\n",
    "    input_ = MEETING_SEG_PROMPT.format_prompt(transcript=transcript_str)\n",
    "\n",
    "    # Generate and log token usage\n",
    "    with get_openai_callback() as api_usage:\n",
    "        output = llm([HumanMessage(content=input_.to_string())])\n",
    "    \n",
    "        # Parse and print parsed\n",
    "        try:\n",
    "            parsed_output = MEETING_SEG_PARSER.parse(output.content)\n",
    "            for section in parsed_output.sections:\n",
    "                print(f\"SECTION LABEL: {section.label}\")\n",
    "                print(f\"FIRST SENTENCE: '{section.first_sentence_text}'\")\n",
    "                print(f\"LAST SENTENCE: '{section.last_sentence_text}'\")\n",
    "\n",
    "                start_sentence_index = -1\n",
    "                end_sentence_index = -1\n",
    "                for i, sentence in enumerate(transcript.sentences):\n",
    "                    if start_sentence_index == -1 and sentence.text == section.first_sentence_text:\n",
    "                        start_sentence_index = i\n",
    "                    if start_sentence_index != -1 and sentence.text == section.last_sentence_text:\n",
    "                        end_sentence_index = i\n",
    "                        break\n",
    "\n",
    "                # Only print if both start and end were found\n",
    "                if start_sentence_index != -1 and end_sentence_index != -1:\n",
    "                    section_text = \" \".join([s.text for s in transcript.sentences[start_sentence_index:end_sentence_index]])\n",
    "                    print(f\"SECTION FULL CONTENT: {section_text}\")\n",
    "                else:\n",
    "                    print(\"SECTION FULL CONTENT: Could not find matching content\")\n",
    "                    \n",
    "                print()\n",
    "                print()\n",
    "            print()\n",
    "            print(\"-\" * 80)\n",
    "            print()\n",
    "\n",
    "            return parsed_output\n",
    "    \n",
    "        except Exception as e:\n",
    "            # Print output\n",
    "            print(\"!!!! ERROR OCCURRED !!!!\")\n",
    "            print()\n",
    "            print(output)\n",
    "            print()\n",
    "            print(\"-\" * 80)\n",
    "            print()\n",
    "            raise e\n",
    "    \n",
    "        finally:\n",
    "            # Print api usage\n",
    "            print(api_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d728245c-f246-4b37-990c-85f5fdf313de",
   "metadata": {},
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ecdb693-7153-41e6-b182-3afa470dde2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SECTION LABEL: SectionLabels.public_comment\n",
      "FIRST SENTENCE: 'Let's go on to public comment.'\n",
      "LAST SENTENCE: 'The public comment period is now closed.'\n",
      "SECTION FULL CONTENT: Could not find matching content\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Tokens Used: 4938\n",
      "\tPrompt Tokens: 4898\n",
      "\tCompletion Tokens: 40\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.14934\n"
     ]
    }
   ],
   "source": [
    "seg = _process_transcript(seattle_df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0eaaa4d-6a20-4d21-b20a-11195dc5131c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SECTION LABEL: SectionLabels.public_comment\n",
      "FIRST SENTENCE: 'So at this time, we will open the general in- person and hybrid public comment.'\n",
      "LAST SENTENCE: 'So I request you to vote no on such an ordinance simply because they don't want to get into caste-based discrimination issues as they might lose their license.'\n",
      "SECTION FULL CONTENT: So at this time, we will open the general in- person and hybrid public comment. Do we have anybody in person? Okay. We've got several folks who are signed up... Sorry. Who are signed up virtually for public comment. So I will remind folks that you need to address things that are on today's agenda. So we do... It does remain the strong intent of Council to have public comment during our regularly scheduled meetings, and the Council reserves the right to modify the public comment period at any point if we deem that the system is being abused. I will moderate the public comment period in the following manner. This comment period will be for up to 20 minutes. Each speaker will be given two minutes. Let's say one minute, because it does look like there are several folks signed up. I'll call on two speakers at a time in the order in which you registered on the Council's website. If you've not yet registered to speak but would like to, you can sign up before the end of the comment period by going to the Council's website at seattle.gov slash Council. Once I call your name, please unmute, and you will receive a prompt if you have been unmuted. At that point, press star 6 to begin speaking. You will hear a chime when you have 10 seconds left. Once you hear the chime, please wrap up your comments so we can move to the next speaker. And when you've completed your public comment, we ask that you disconnect, and if you would like to continue following the meeting, that you do so via Seattle Channel. Okay. So the public comment period is now open, and I will call the first person. As I said, we don't have anybody signed up in advance. So I will call the first person. The first person I see is Sri Ravi. Yes. Can you hear me? Yes, Sri. Please go ahead. You have one minute. Thank you. I just wanted to say that I'm requesting all the people in the room to please raise your hand if you don't know on the caste ordinance because it disproportionately impacts Indian children in the U.S. and leads to harassment, assault, and discrimination on a community that's a victim of centuries of horrendous colonial atrocities. It is recorded that the British actually introduced caste as a part of the divide and rule policy, and when they asked for the caste, they said it was the British who introduced it. And this is all documented by the British themselves. Excuse me. And it's also noted that Solomon and Hickel looked at a 40-year period during colonialism, and they found that 165 million Indians perished during this period. So, anyway, please consider the socioeconomic problems that are created by colonialism and don't take it personally. Thank you. Thank you. The next speaker is Sri C. And you will be followed by Dimitri Potemkin. Hi. This is Sri. Can you all hear me? Yes. Hi. I'd like to express my serious concerns regarding the caste discrimination ordinance that's being introduced by Council Member Kshama Sawant. The premise for introducing this ordinance we have been hearing are anecdotal evidence. For instance, a quality lab study that was quoted in support of this ordinance has been severely debunked by Carnegie Endowment Research. It said that the survey is not based on a representative sample and raised serious concerns about questions about the generalizability of its findings. Along similar lines, one of the key findings of the Pew Research is that people of lower caste do not think they face discrimination based on caste. So I sincerely request all the Council Members to vote no on this proposed ordinance. Thank you. Thank you. The next speaker is Dimitri Potemkin followed by Pita Prasad. Good morning. I wanted to say that with this caste ordinance, the Seattle City Council is writing lawsuits just like with what happened with Cal State in their lawsuit. Professor Sunil Kumar and Praveen Sinha claim that Cal State's new caste discrimination policy, quote, seeks to define the Hindu religion as including caste and an alleged oppressive and discriminatory caste system as foundational religious tenets and that it singles out students and staff who are Indian and Hindu. Kumar and Sinha don't identify as being members of any caste and they said they fear that their caste identity will be lost to them under the policy. Both professors were born in India and are followers of Hinduism. I will add that my Indian wife's family never had caste identity in their community. She has no caste. This Council ought to refrain from meddling in lives and histories and cultures that it doesn't understand. Thank you. Thank you. The next speaker is Pita Prasad. Followed by Ashwin Arab. Hi. Can you hear me? Yes. Okay. So I'm calling to really ask our Council members to vote no on the caste ordinance. You have already been contacted by several Dalit and Bahujan folks, the ones you are claiming to protect and represent, and all of those Dalit Bahujan folks have urged you to not fall for this racist trope. They do not need representation from the likes of Equality Labs, which is an open hate group dedicated to demolishing Hinduism. That is their right. Seattle should not mainstream such hate and such racist trope. As previous scholars have said, those opposing it are not for discrimination, but they want to warn you not to set up a commission or a law that would start to discriminate against yet another minority. Most bad people start with very good intentions. So while most of you are acting with good intentions, please be aware of the ramifications of what you are doing. Thank you. Vote no. The next speaker is Ashwin Arab. Hi. My name is Ashwin, and I'm calling in to urge the Seattle City Council to vote no on the caste ordinance. Caste in South Asian communities is far removed from the American cultural context and not easy to legislate morally. One of my main concerns is how this law will actually be enforced. There are no universally applicable ways to determine someone's caste. I don't even know my caste. As a South Asian American, is the Seattle City Council going to assign me one? If so, how would they determine my caste? Will you force South Asians to identify that way? And lastly, how will this apply to ethnically mixed people? If the council has not considered these questions, I would urge them to table it until more studies have been conducted as it may have possible ramifications for the very people it claims to help. Thank you. The next speaker is Rajeshwari G. Namaste. My name is Rajeshwari, and I'm against the caste ordinance. To our respected council members, I ask, if you are tired of hearing the cause, think of what happens if this ordinance is passed. A huge number of lawsuits and counter lawsuits are sure to follow. How do we resolve them? How do we determine someone's caste? And who decides if a person is higher or lower caste? To my Hindu friends, I have the same questions. Caste is a foreign word, and in its insidiousness, all discrimination comes from a place of arrogance and ignorance. While there is little we can do about the former, there is a lot we can do about the latter. So please educate yourself and those around you. Please do not let a few bad words of ignorant individuals cloud your thinking. May we all go from the darkness of ignorance to the light of knowledge. Thank you very much. Thank you. The next speaker is Chitana Wilson. Hi, my name is Chitana, and I strongly urge the Seattle Council to vote no on the caste resolution, again, as it is founded on faulty data. There are several well-documented problems with the Equality Lab survey as laid out in various articles. The quality and data of this report were challenged comprehensively back in 2018 when it was first distributed. More recently, the 2020 survey on Indian Americans by the Seattle Council found that Indian Americans were more likely to be cast in the South Asian population than non-Indian Americans. The study relied on a non-representative snowball sampling method to recruit respondents. Furthermore, respondents who did not disclose a caste identity were dropped from the data set. Therefore, it is likely that the sample did not fully represent the South Asian American population. I would like to call on a caste writer. Caste is rooted in the Hindu scriptures. She is seeking to dismantle Hinduism, and I just want to know if Seattle supports dismantling Hinduism as well. Thank you. Thank you. The next speaker is Srinivas Goodlava Ledi. Srinivas, are you with us? Apologies if I'm mispronouncing your name. Okay. I've got three folks listed next who are not present, so Venky Ram. Hello. Hello. Hello. This is Srinivas here. Yes. Please go ahead. Yeah. Thank you. I was pressing the wrong button. I'm on mute. Okay. Good evening, council members, Seattle City Council members. Yeah, I would like to say, just make it short and simple. Please vote no on the vote to the caste ordinance which Seattle City is planning to do. It's very much like CRT thing, which is coming in the year schools, which is going to invite more lawsuits, more discrimination. We're going to create more bad blood among the American citizens. Most of us are coming from immigrants like myself. We are now Americanized. My kids are Americanized. They have been educated in the U.S. All their education has been in nobody asked their caste. Now with this, they'll be caste tagged. And that's going to be a problem for the future generations. We are doing more. This ordinance is going to pump up more hatred among the Americans who are born here with different backgrounds. Yes. This is absolutely a no. It's going to invite more trouble for Americans going down the future. Yep. That's my take. And there are already enough people in the U.S. to protect every citizen. Thank you. Your time is ended. Thank you very much. So the next three folks I have are not listed as not present. Venky Ram, Atul Jandale. I'm sure Spanish accent is not how you pronounce it. My apologies. And Rachel Gotham. If you are interested still, you still have time to call in. So the next speaker will be Vidula Vajramushti. Good morning. My name is Vidula Vajramushti. I'm calling here to request you to vote no on the caste-based ordinance. So I am directly impacted by this as an ex-Microsoft employee and my spouse who currently works for Amazon. So this caste-based ordinance would single not only Hindu-Americans but the entire South Asian community. I urge city council members to vote no on such an ordinance simply because this will invite a number of financial lawsuits to cities, to businesses, and this may, in fact, result in, you know, businesses not hiring people of South Asian backgrounds simply because they don't want to get into caste based organizations.\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Tokens Used: 2965\n",
      "\tPrompt Tokens: 2892\n",
      "\tCompletion Tokens: 73\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.09113999999999998\n"
     ]
    }
   ],
   "source": [
    "seg = _process_transcript(seattle_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b6221ab-aa31-4fa4-a1b9-66b2c1732d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-kzj3voQusmCX8xQilGiEbeXI on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-kzj3voQusmCX8xQilGiEbeXI on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-kzj3voQusmCX8xQilGiEbeXI on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SECTION LABEL: SectionLabels.public_comment\n",
      "FIRST SENTENCE: 'At this time, we're going to move into public comment.'\n",
      "LAST SENTENCE: 'And I please ask you to do something about this. Thank you.'\n",
      "SECTION FULL CONTENT: Could not find matching content\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Tokens Used: 3498\n",
      "\tPrompt Tokens: 3447\n",
      "\tCompletion Tokens: 51\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.10647\n"
     ]
    }
   ],
   "source": [
    "seg = _process_transcript(seattle_df, 7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
