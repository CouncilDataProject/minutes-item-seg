{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7475a584-99a1-4ae2-bfca-f152e39a09ca",
   "metadata": {},
   "source": [
    "# Public Comment Period Segmentation via GPT-3.5-Turbo-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b594c8-4821-404c-81bf-841350af0e75",
   "metadata": {},
   "source": [
    "## Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b36f2b86-84b4-4000-8c21-94f9a4e27f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>meta</th>\n",
       "      <th>true_masses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We are recording. Wonderful. Okay. Good aftern...</td>\n",
       "      <td>{'event_id': '84bfb428c005', 'session_id': 'c4...</td>\n",
       "      <td>[1046, 563, 41062]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good afternoon, everybody. Today is Tuesday, M...</td>\n",
       "      <td>{'event_id': 'c86c94ed1db7', 'session_id': 'c6...</td>\n",
       "      <td>[8847, 11850, 7373]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good afternoon, everyone, the September 14th, ...</td>\n",
       "      <td>{'event_id': 'fa3fd088de8e', 'session_id': '7c...</td>\n",
       "      <td>[4282, 12860, 21504]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Discussion. 228, council meeting will come her...</td>\n",
       "      <td>{'event_id': '7cc7c93e7a63', 'session_id': 'f7...</td>\n",
       "      <td>[141623]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you. Have a great day. Good morning, eve...</td>\n",
       "      <td>{'event_id': 'c511fea02999', 'session_id': '93...</td>\n",
       "      <td>[447, 3749, 72862]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thank you very much. Thank you. The December 6...</td>\n",
       "      <td>{'event_id': '2adc154d91b0', 'session_id': '6d...</td>\n",
       "      <td>[1537, 7617, 3517, 1938, 18775]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thank you, son. Good afternoon, everybody. It'...</td>\n",
       "      <td>{'event_id': '4477546b534d', 'session_id': '72...</td>\n",
       "      <td>[1087, 8777, 2406]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Good afternoon, the September 21st, 2020 meeti...</td>\n",
       "      <td>{'event_id': '6562c700d929', 'session_id': '97...</td>\n",
       "      <td>[12166, 34099, 59278]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Director Sawyer is ready to ready to go. After...</td>\n",
       "      <td>{'event_id': 'fc5983dfdc1f', 'session_id': 'cd...</td>\n",
       "      <td>[3744, 11233, 11469, 7982, 40536]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Budget meeting starting in a moment. I will ca...</td>\n",
       "      <td>{'event_id': '23333c839436', 'session_id': '3b...</td>\n",
       "      <td>[10222, 12327, 102269]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Good morning, everybody. The March 3, 2021 mee...</td>\n",
       "      <td>{'event_id': '749503d88894', 'session_id': 'f6...</td>\n",
       "      <td>[1671, 10938, 1491, 1725, 144754]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The May 11th, 2022 meeting of the Seattle City...</td>\n",
       "      <td>{'event_id': 'b5e3673a68ff', 'session_id': 'c9...</td>\n",
       "      <td>[3133, 3043, 59419]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   We are recording. Wonderful. Okay. Good aftern...   \n",
       "1   Good afternoon, everybody. Today is Tuesday, M...   \n",
       "2   Good afternoon, everyone, the September 14th, ...   \n",
       "3   Discussion. 228, council meeting will come her...   \n",
       "4   Thank you. Have a great day. Good morning, eve...   \n",
       "5   Thank you very much. Thank you. The December 6...   \n",
       "6   Thank you, son. Good afternoon, everybody. It'...   \n",
       "7   Good afternoon, the September 21st, 2020 meeti...   \n",
       "8   Director Sawyer is ready to ready to go. After...   \n",
       "9   Budget meeting starting in a moment. I will ca...   \n",
       "10  Good morning, everybody. The March 3, 2021 mee...   \n",
       "11  The May 11th, 2022 meeting of the Seattle City...   \n",
       "\n",
       "                                                 meta  \\\n",
       "0   {'event_id': '84bfb428c005', 'session_id': 'c4...   \n",
       "1   {'event_id': 'c86c94ed1db7', 'session_id': 'c6...   \n",
       "2   {'event_id': 'fa3fd088de8e', 'session_id': '7c...   \n",
       "3   {'event_id': '7cc7c93e7a63', 'session_id': 'f7...   \n",
       "4   {'event_id': 'c511fea02999', 'session_id': '93...   \n",
       "5   {'event_id': '2adc154d91b0', 'session_id': '6d...   \n",
       "6   {'event_id': '4477546b534d', 'session_id': '72...   \n",
       "7   {'event_id': '6562c700d929', 'session_id': '97...   \n",
       "8   {'event_id': 'fc5983dfdc1f', 'session_id': 'cd...   \n",
       "9   {'event_id': '23333c839436', 'session_id': '3b...   \n",
       "10  {'event_id': '749503d88894', 'session_id': 'f6...   \n",
       "11  {'event_id': 'b5e3673a68ff', 'session_id': 'c9...   \n",
       "\n",
       "                          true_masses  \n",
       "0                  [1046, 563, 41062]  \n",
       "1                 [8847, 11850, 7373]  \n",
       "2                [4282, 12860, 21504]  \n",
       "3                            [141623]  \n",
       "4                  [447, 3749, 72862]  \n",
       "5     [1537, 7617, 3517, 1938, 18775]  \n",
       "6                  [1087, 8777, 2406]  \n",
       "7               [12166, 34099, 59278]  \n",
       "8   [3744, 11233, 11469, 7982, 40536]  \n",
       "9              [10222, 12327, 102269]  \n",
       "10  [1671, 10938, 1491, 1725, 144754]  \n",
       "11                [3133, 3043, 59419]  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load annotated dataset\n",
    "df = pd.read_json(\"trial-datasets/seattle-public-comment-period-seg-v0.jsonl\", lines=True)\n",
    "\n",
    "# Prep dataset for eval\n",
    "prepped_eval_rows = []\n",
    "for _, row in df.iterrows():\n",
    "    # Get text\n",
    "    text = row[\"text\"]\n",
    "    \n",
    "    # Get meta\n",
    "    meta = row[\"meta\"]\n",
    "\n",
    "    # Construct masses\n",
    "    masses = []\n",
    "    prev_index = 0\n",
    "    if isinstance(row[\"spans\"], list):\n",
    "        for span in row[\"spans\"]:\n",
    "            # Choose what index to get based off label\n",
    "            if span[\"label\"] == \"FIRST-SENTENCE\":\n",
    "                # Get start index\n",
    "                mass_calc_index = span[\"start\"]\n",
    "            else:\n",
    "                # Get end index\n",
    "                mass_calc_index = span[\"end\"]\n",
    "\n",
    "            # Add masses to list\n",
    "            masses.append(mass_calc_index - prev_index)\n",
    "\n",
    "            # Update prev index\n",
    "            prev_index = mass_calc_index\n",
    "        \n",
    "        # Add final mass\n",
    "        masses.append(len(text) - prev_index)\n",
    "    else:\n",
    "        # Add mass for full text\n",
    "        masses.append(len(text))\n",
    "\n",
    "    # Add to list\n",
    "    prepped_eval_rows.append({\n",
    "        \"text\": row[\"text\"],\n",
    "        \"meta\": row[\"meta\"],\n",
    "        \"true_masses\": masses,\n",
    "    })\n",
    "\n",
    "# Convert to dataframe\n",
    "prepped_eval_df = pd.DataFrame(prepped_eval_rows)\n",
    "# prepped_eval_df = prepped_eval_df.sample(3)\n",
    "prepped_eval_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f991adf3-645e-463c-927a-1fd2aa3c2be1",
   "metadata": {},
   "source": [
    "## Prompt Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e792af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eva/miniforge-pypy3/envs/minutes-item-seg/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import backoff\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatAnthropic, ChatOpenAI\n",
    "from langchain.chat_models.base import BaseChatModel\n",
    "from langchain.llms import HuggingFaceEndpoint\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "import spacy\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "load_dotenv()\n",
    "# llm = ChatAnthropic(model=\"claude-2.0\", temperature=0, max_tokens_to_sample=4096)\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0, max_tokens=4096)\n",
    "llm = HuggingFaceEndpoint(\n",
    "    endpoint_url=\"https://boxjj56zj0zbbjue.us-east-1.aws.endpoints.huggingface.cloud\",\n",
    "    task=\"text2text-generation\",\n",
    ")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "class PublicCommentPeriod(BaseModel):\n",
    "    first_sentence_text: str | None = Field(\n",
    "        description=\"the text of the sentence which introduces the public comment period, or null if no public comment period was found\",\n",
    "    )\n",
    "    last_sentence_text: str | None = Field(\n",
    "        description=\"the text of the sentence which concludes the public comment period, or if null no public comment period was found\",\n",
    "    )\n",
    "\n",
    "class MultiPublicCommentPeriod(BaseModel):\n",
    "    periods: list[PublicCommentPeriod] = Field(\n",
    "        description=\"the list of public comment periods (sometimes also called public hearings)\",\n",
    "    )\n",
    "\n",
    "PUBLIC_COMMENT_PERIOD_SEG_PARSER = PydanticOutputParser(pydantic_object=MultiPublicCommentPeriod)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "PUBLIC_COMMENT_PERIOD_SEG_PROMPT = PromptTemplate.from_file(\n",
    "    \"prompts/v0-public-comment-period-seg.jinja\",\n",
    "    input_variables=[\"transcript\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": PUBLIC_COMMENT_PERIOD_SEG_PARSER.get_format_instructions(),\n",
    "    },\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "@backoff.on_exception(backoff.expo, json.JSONDecodeError, max_tries=3)\n",
    "def _process_transcript(text: str) -> list[int]:\n",
    "    # Convert text to sentences\n",
    "    sentences = list(nlp(text).sents)\n",
    "\n",
    "    # Convert to prompt ready string\n",
    "    transcript_str = \"\\n\\n\".join([sent.text for sent in sentences[:300]])\n",
    "\n",
    "    # Fill the prompt\n",
    "    input_ = PUBLIC_COMMENT_PERIOD_SEG_PROMPT.format_prompt(transcript=transcript_str)\n",
    "\n",
    "    # Generate\n",
    "    if isinstance(llm, BaseChatModel):\n",
    "        # Generate\n",
    "        output = llm([HumanMessage(content=input_.to_string())]).content\n",
    "    else:\n",
    "        # Generate\n",
    "        output = llm(input_.to_string())\n",
    "\n",
    "    # Parse output\n",
    "    try:\n",
    "        pc_periods = PUBLIC_COMMENT_PERIOD_SEG_PARSER.parse(output)\n",
    "\n",
    "    except:\n",
    "        print(output)\n",
    "        raise Exception(\"Failed to parse output\")\n",
    "\n",
    "    # Process all periods found\n",
    "    prev_index = 0\n",
    "    predicted_masses = []\n",
    "    for pc_period in pc_periods.periods:\n",
    "        # Process masses\n",
    "        if (\n",
    "            pc_period.first_sentence_text is not None\n",
    "            and pc_period.last_sentence_text is not None\n",
    "        ):\n",
    "            first_sentence_index = text.find(pc_period.first_sentence_text)\n",
    "            predicted_masses.append(first_sentence_index - prev_index)\n",
    "            prev_index = first_sentence_index\n",
    "\n",
    "            last_sentence_index = text.find(pc_period.last_sentence_text)\n",
    "            predicted_masses.append(last_sentence_index - prev_index)\n",
    "            prev_index = last_sentence_index\n",
    "\n",
    "    # Add final mass (or full text as mass)\n",
    "    if len(predicted_masses) == 0:\n",
    "        predicted_masses.append(len(text))\n",
    "    else:\n",
    "        predicted_masses.append(len(text) - prev_index)\n",
    "\n",
    "    return predicted_masses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d728245c-f246-4b37-990c-85f5fdf313de",
   "metadata": {},
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "625e7188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:20<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "t\n",
      "t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "t\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to parse output",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge-pypy3/envs/minutes-item-seg/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:27\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     26\u001b[0m     json_str \u001b[39m=\u001b[39m match\u001b[39m.\u001b[39mgroup()\n\u001b[0;32m---> 27\u001b[0m json_object \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(json_str, strict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     28\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpydantic_object\u001b[39m.\u001b[39mparse_obj(json_object)\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/minutes-item-seg/lib/python3.11/json/__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m     kw[\u001b[39m'\u001b[39m\u001b[39mparse_constant\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m parse_constant\n\u001b[0;32m--> 359\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\u001b[39m.\u001b[39;49mdecode(s)\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/minutes-item-seg/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/minutes-item-seg/lib/python3.11/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb#X25sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb#X25sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     pc_periods \u001b[39m=\u001b[39m PUBLIC_COMMENT_PERIOD_SEG_PARSER\u001b[39m.\u001b[39;49mparse(output)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb#X25sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/minutes-item-seg/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:33\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     32\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to parse \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m from completion \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m. Got: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 33\u001b[0m \u001b[39mraise\u001b[39;00m OutputParserException(msg, llm_output\u001b[39m=\u001b[39mtext)\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Failed to parse MultiPublicCommentPeriod from completion \n\n\n\n\n\n\n\n\n\nt\nt\n\n\n\n\nt\n. Got: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m _, row \u001b[39min\u001b[39;00m tqdm(prepped_eval_df\u001b[39m.\u001b[39miterrows(), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(prepped_eval_df)):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# Get masses\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     predicted_masses \u001b[39m=\u001b[39m _process_transcript(row[\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# Get similarity\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     sim \u001b[39m=\u001b[39m segeval\u001b[39m.\u001b[39mboundary_similarity(row[\u001b[39m\"\u001b[39m\u001b[39mtrue_masses\u001b[39m\u001b[39m\"\u001b[39m], predicted_masses, n_t\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(row[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m*\u001b[39m \u001b[39m0.07\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/minutes-item-seg/lib/python3.11/site-packages/backoff/_sync.py:105\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m details \u001b[39m=\u001b[39m {\n\u001b[1;32m     97\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m: target,\n\u001b[1;32m     98\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m: args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39melapsed\u001b[39m\u001b[39m\"\u001b[39m: elapsed,\n\u001b[1;32m    102\u001b[0m }\n\u001b[1;32m    104\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     ret \u001b[39m=\u001b[39m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    106\u001b[0m \u001b[39mexcept\u001b[39;00m exception \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    107\u001b[0m     max_tries_exceeded \u001b[39m=\u001b[39m (tries \u001b[39m==\u001b[39m max_tries_value)\n",
      "\u001b[1;32m/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb#X25sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb#X25sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     \u001b[39mprint\u001b[39m(output)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb#X25sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFailed to parse output\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb#X25sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39m# Process all periods found\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/eva/active/cdp/minutes-item-seg/public-comment-period-seg.ipynb#X25sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m prev_index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mException\u001b[0m: Failed to parse output"
     ]
    }
   ],
   "source": [
    "import segeval\n",
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "for _, row in tqdm(prepped_eval_df.iterrows(), total=len(prepped_eval_df)):\n",
    "    # Get masses\n",
    "    predicted_masses = _process_transcript(row[\"text\"])\n",
    "\n",
    "    # Get similarity\n",
    "    sim = segeval.boundary_similarity(row[\"true_masses\"], predicted_masses, n_t=int(len(row[\"text\"]) * 0.07))\n",
    "\n",
    "    # Get confusion matrix\n",
    "    matrix = segeval.boundary_confusion_matrix(row[\"true_masses\"], predicted_masses, n_t=int(len(row[\"text\"]) * 0.07))\n",
    "\n",
    "    # Get precision, recall, and f1\n",
    "    precision = segeval.precision(matrix)\n",
    "    recall = segeval.recall(matrix)\n",
    "    f1 = segeval.fmeasure(matrix)\n",
    "\n",
    "    # Add to results\n",
    "    results.append({\n",
    "        \"text\": row[\"text\"],\n",
    "        \"meta\": row[\"meta\"],\n",
    "        \"true_masses\": row[\"true_masses\"],\n",
    "        \"predicted_masses\": predicted_masses,\n",
    "        \"similarity\": sim,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    })\n",
    "\n",
    "# Convert to dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Mean Similarity:\", results_df[\"similarity\"].mean())\n",
    "print(\"Mean Precision:\", results_df[\"precision\"].mean())\n",
    "print(\"Mean Recall:\", results_df[\"recall\"].mean())\n",
    "print(\"Mean F1:\", results_df[\"f1\"].mean())\n",
    "print()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[[\"true_masses\", \"predicted_masses\", \"similarity\", \"f1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09944c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
